{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqa\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "CONN_STRING = 'postgresql+psycopg2://postgres:postgres@localhost:5432/datasets'\n",
    "engine = sqa.create_engine(CONN_STRING)\n",
    "\n",
    "# Fetch negative class data from the 'negative' table\n",
    "SQL = \"SELECT * FROM ccfd.combined\"\n",
    "df = pd.read_sql(SQL, engine)\n",
    "\n",
    "X = df.drop('class', axis=1)  # Assuming the target column is named 'class'\n",
    "y = df['class']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class FraudDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FraudDetectionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 8)  # New layer\n",
    "        self.fc5 = nn.Linear(8, 1)   # Update this layer to match the output of the new layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))  # Ensure the new layer is included in the forward pass\n",
    "        x = self.sigmoid(self.fc5(x))\n",
    "        return x\n",
    "    \n",
    "def train_model(X_train, y_train, model_class):\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to('cuda')\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to('cuda')\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = model_class().to('cuda')\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 5\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to('cuda')\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "\n",
    "    accuracy = accuracy_score(y_test_tensor.cpu(), predictions.cpu())\n",
    "    precision = precision_score(y_test_tensor.cpu(), predictions.cpu())\n",
    "    recall = recall_score(y_test_tensor.cpu(), predictions.cpu())\n",
    "    f1 = f1_score(y_test_tensor.cpu(), predictions.cpu())\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return confusion_matrix(y_test_tensor.cpu(), predictions.cpu()), accuracy, precision, recall, f1\n",
    "\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Fraud\", \"Fraud\"], yticklabels=[\"Non-Fraud\", \"Fraud\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "# FraudDetectionModel on Original dataset\n",
    "print(\"\\nTraining and evaluating FraudDetectionModel on Original dataset...\")\n",
    "model = train_model(X_train, y_train, FraudDetectionModel)\n",
    "cm, accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)\n",
    "plot_confusion_matrix(cm, \"Confusion Matrix for FraudDetectionModel on Original dataset\")\n",
    "print(\"FraudDetectionModel has been trained, evaluated and saved successfully on Original dataset.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
